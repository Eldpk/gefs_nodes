import xarray as xr
import numpy as np
import pprint

from minisom import MiniSom
from sklearn.preprocessing import RobustScaler


def read_and_transform(config, long_fmt='360'):
    """`Reads in the GEFS filename and subsets the data based on the configuration 
    dictionary. This function subsets by coordinates and variable name.
    
    Parameters:
        config: dict
            Dictionary containing lat / lon bounds, filename, and variables. Variables should 
            be individual strings within a list!
        long_fmt: str
            Format of longitude degrees. Default 360.
    
    Returns:
        data_in: xarray dataset
            xarray representation of the GEFS dataset.
        npy: numpy ndarray
            numpy representation of the GEFS dataset.
    """

    var_list = config['vars']
    data_in = xr.open_dataset(config['filename'])[var_list]
    
    if long_fmt == '360':
        data_in = data_in.sel(lon=slice(config['wlon'], config['elon']), 
                              lat=slice(config['nlat'], config['slat']))
    else:
        raise ValueError("-180 to 180 not implemented yet, use 0-360")
        
    data_in = data_in.squeeze()

    # shape: (time, lat, lon, ...) -> iterates along first axis
    
    arrs = [data_in[v].values for v in variables]
    
    processed_list = []
    for i in range(len(data_in.time)):
        timestep = np.concatenate([a[i].flatten() for a in arrays])
        processed_list.append(timestep)
    
    npy = np.array(processed_list)
    
    return data_in, npy

def build_scaler(config):
    """`Reads in the GEFS data based on the filename and configuration
    and then preprocesses the data by applying a percentile scaler to
    normalize the data. This should help address outlier impacts
    regardless of the variable used.
    
    Parameters:
        config: dict
            Dictionary containing lat / lon bounds and variable name.
            
    Return:
        training_ds: xarray dataset
            xarray representation of the GEFS data.
        training_npy: numpy ndarray
            numpy representation of GEFS data.
        scale: RobustScaler
            trained scaler used for training and prediction.
    """
    
    #read in the file and get a flattened representation
    training_ds, training_npy = read_and_transform(config)
    
    #define the scaler that transforms the data
    scale = RobustScaler()

    #fit the scaler that transforms the data
    scale.fit(training_npy)

    return training_ds, training_npy, scale

def train_som(preferences):
    """Trains the SOM by reading in the data based on 
    the preferences and performs preprocessing tasks
    and provides training output messages.
    
    Parameters:
        filename: str
            Absolute or relative location of a GEFS file.
        config: dict
            Dictionary containing lat / lon bounds and variable name.
            
    Returns:
        som: MiniSom model
            Trained SOM model.
        scaler: RobustScaler
            The trained scaler used in training.
        post_preferences: dict
            Updated preferences that include trained SOM config data
            and training data.
        ds: xarray dataset
            The xarray representation of the GEFS data.
    """

    ds, npy, scaler = build_scaler(preferences)

    scaled_npy = scaler.transform(npy)

    preferences['som_config']['input_len'] = len(preferences['vars']) * ds.sizes['lon'] * ds.sizes['lat']
    preferences['som_train']['data'] = scaled_npy
    
    print("current model configuration")
    pprint.pprint(preferences['som_config'])
    print("current training configuration")
    pprint.pprint(preferences['som_train'])
    
    som = MiniSom(**preferences['som_config'])
    som.train(**preferences['som_train'])

    return som, scaler, preferences, ds